{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/pydev/Music/work_files/latest_broko_code/training/test/hyperparametertuning_lgb.ipynb Cell 1\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pydev/Music/work_files/latest_broko_code/training/test/hyperparametertuning_lgb.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pydev/Music/work_files/latest_broko_code/training/test/hyperparametertuning_lgb.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/pydev/Music/work_files/latest_broko_code/training/test/hyperparametertuning_lgb.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlightgbm\u001b[39;00m \u001b[39mimport\u001b[39;00m LGBMRegressor, Dataset\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pydev/Music/work_files/latest_broko_code/training/test/hyperparametertuning_lgb.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_absolute_percentage_error \u001b[39mas\u001b[39;00m MAPE\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pydev/Music/work_files/latest_broko_code/training/test/hyperparametertuning_lgb.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m LabelEncoder\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor, Dataset\n",
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/pydev/Music/work_files/latest_broko_code\"\n",
    "df = pd.read_csv(path  + \"/Dataset/ML_CLEAN_DATA__Bdv2.2_RES.csv\")\n",
    "df.info(verbose=True,show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"ML_Number\",\"Postal_Code\",\"Sold_Price\",\"Month_Year\",\"HPI_for_Month\"]\n",
    "df = df.drop(drop_cols, axis=1)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.dropna(axis = 0, how ='any') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = data['HPI_Sold_Price'].quantile(0.25)\n",
    "q3 = data['HPI_Sold_Price'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "lower_bound_outliers = data[data['HPI_Sold_Price'] < lower_bound] \n",
    "upper_bound_outliers = data[data['HPI_Sold_Price'] > upper_bound]\n",
    "# lower_bound_outliers.to_csv(path + '/Dataset/lower_bound_outliers.csv')\n",
    "# upper_bound_outliers.to_csv(path +'/Dataset/upper_bound_outliers.csv')    \n",
    "dataset = data[(data['HPI_Sold_Price'] >= lower_bound) & (data['HPI_Sold_Price'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info(verbose=True,show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('HPI_Sold_Price',axis=1)\n",
    "y = dataset['HPI_Sold_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical features\n",
    "categorical_features = [column for column, dtype in X.dtypes.items() if dtype==object]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LightGBM model\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 30),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.5),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 5, 50),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 1),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 1),\n",
    "    }\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Encode categorical features before training\n",
    "    label_encoders = {}\n",
    "    for feature in categorical_features:\n",
    "        le = LabelEncoder()\n",
    "        X_train[feature] = le.fit_transform(X_train[feature])\n",
    "        X_valid[feature] = le.fit_transform(X_valid[feature])\n",
    "        label_encoders[feature] = le\n",
    "\n",
    "    model = LGBMRegressor(**params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        categorical_feature=categorical_features,\n",
    "        early_stopping=10,  # Early stopping rounds\n",
    "        verbose=False) # Set verbose to False to suppress LightGBM's messages\n",
    "    \n",
    "\n",
    "    y_pred = model.predict(X_valid)\n",
    "\n",
    "    return MAPE(y_valid, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Optuna study\n",
    "\n",
    "sampler = TPESampler(seed=123)\n",
    "study = optuna.create_study(direction='minimize', sampler=sampler)\n",
    "\n",
    "# Optimize the objective function\n",
    "study.optimize(objective, n_trials=100,show_progress_bar=True)\n",
    "\n",
    "# Get the best parameters and model type\n",
    "best_params = study.best_params\n",
    "\n",
    "# Print the best model and its parameters\n",
    "print(\"Best hyperparameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df = pd.DataFrame([best_params])\n",
    "best_df.to_csv(path + \"/Dataset/best_lgb.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "broko",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
